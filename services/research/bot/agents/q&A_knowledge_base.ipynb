{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader,TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "from openai import OpenAI\n",
    "import requests\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from typing import List, Union, Dict, Optional\n",
    "from pinecone import Index\n",
    "\n",
    "import validators\n",
    "import requests\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_API_ENV = os.getenv(\"PINECONE_API_ENV\")\n",
    "PINECONE_QA_BASE_INDEX_NAME = os.getenv(\"PINECONE_QA_BASE_INDEX_NAME\")\n",
    "PINECONE_KNOWLEDGE_BASE_INDEX_NAME = os.getenv(\"PINECONE_KNOWLEDGE_BASE_INDEX_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client Initialisation\n",
    "Now, we will be using the openAI client to get embeddings, as we would be needing in our model along with neccessary intialisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "openAI_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "embedding_model = openAI_client.embeddings\n",
    "pc = Pinecone(api_key = PINECONE_API_KEY, environment = PINECONE_API_ENV)\n",
    "index = pc.Index(PINECONE_QA_BASE_INDEX_NAME)\n",
    "\n",
    "def get_embedding(text) :\n",
    "    \"\"\"\n",
    "        Function to convert the text string into embeddings using text-embedding-3-small from OpenAI\n",
    "    \n",
    "        Args:\n",
    "            text : A string which will contain either the text chunk or the user query\n",
    "            \n",
    "        Returns:\n",
    "            vector : A vector of 1536 dimensions\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = embedding_model.create(\n",
    "            input=text,\n",
    "            model=\"text-embedding-3-small\"\n",
    "        )\n",
    "        \n",
    "        return response.data[0].embedding   \n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(str(e))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to use the above, we need to create these functions as a collective tool, which can be used by an agent to query the vector DB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Creation\n",
    "Now, we would have to create tools for this purpose, as asynchronus functions which await till the vector DB is loaded and then query the vector DB, evnetually returning the relevant texts. As the admin id will be a fixed one, we will be directly referring it from the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_pairs(query):\n",
    "    query_vector = get_embedding(query)\n",
    "    \n",
    "    results = index.query(\n",
    "        vector = query_vector,\n",
    "        top_k = 10,\n",
    "        include_values = False,\n",
    "        include_metadata = True,\n",
    "        filter={\n",
    "            \"ADMIN_ID\" : os.getenv('ADMIN_ID_QA'),\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    relevant_pairs = []\n",
    "    for record in results['matches']:\n",
    "        pair = {}\n",
    "        pair['id'] = record['metadata']['QA_ID']\n",
    "        pair['score'] = record['score']\n",
    "        pair['question'] = record['metadata']['question']\n",
    "        pair['answer'] = record['metadata']['answer']\n",
    "        relevant_pairs.append(pair)\n",
    "    \n",
    "    return relevant_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the answer generation, let us now set the system instructions for the LLM model, which would be used to generate the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instructions = \"\"\"\n",
    "    You are a specialised AI context aware doubt solver working at an edtech startup, and you will be assisting the users to answer their queries based on previous intrcutors and TAs solved queries.\n",
    "    You will be given a query by the user and the top relevant documents and you have to use those to answer the query asked by the user, which will be given to you below. \n",
    "    In the relevant documents,you will be given the id of the conversation, the cosine similarity score, the question which was aksed by previous student and the answers by the TAs, along with the id of the QA pair. \n",
    "    YOU MUST tell the user that they can explore this further by going to that thread (give them the id) and looking at the entire conversation for better understanding. (Think of this as a reference to build authenticity, as you mention the id).\n",
    "    \n",
    "    MAKE SURE YOU DO NOT ANSWER FROM ANYTHING APART FROM THE DOCUMENTS GIVEN TO YOU. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we would also need the query prompt created from a prompt template, by which we can dynamically populate the query prompt with the relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prompt_template = \"\"\"\n",
    "    \\n\\n User Query : {query}\n",
    "    \\n\\n Documents : {documents}\n",
    "\"\"\"\n",
    "\n",
    "query_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\",\"documents\"],\n",
    "    template=query_prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistant API \n",
    "Now, we have an assistant ready to be used, which can be used to go through the query and relevant documents, and then generate the answers. We will be using hitting the assistant with an API call, and then getting the answers from the assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "openAI_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "assistant_id = os.getenv(\"QA_OPENAI_ASSISTANT_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will be building the function to answer the queries from the assistant, which would be an asynchronus function on a thread as we aim to fetch the answer from the assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = openAI_client.beta.threads.create()\n",
    "\n",
    "def fetch_answer(final_prompt):\n",
    "    openAI_client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content= [{\n",
    "            \"type\" : \"text\",\n",
    "            \"text\" : final_prompt\n",
    "        }]\n",
    "    )\n",
    "            \n",
    "    run = openAI_client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant_id,\n",
    "    )\n",
    "    \n",
    "    while True:\n",
    "        run = openAI_client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "        if run.status == 'completed':\n",
    "            messages = openAI_client.beta.threads.messages.list(\n",
    "                thread_id=thread.id\n",
    "            )\n",
    "            return messages.data[0].content[0].text.value\n",
    "        elif run.status in ['failed', 'cancelled', 'expired']:\n",
    "            raise Exception(f\"Run ended with status: {run.status}\")\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent\n",
    "Now, we will have to make the tools for the agent and make it ready to be used. We will be using the agent to fetch the user query (ideally, this would be coming in from the supervisor), and then we will be using the agent to fetch the answers from the assistant (eventually to be sent back to the supervisor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def answer_query(query):\n",
    "    \"\"\"\n",
    "        Find relevant documents for a given query and userID.\n",
    "        \n",
    "        Args:\n",
    "        - query: The search query\n",
    "        \n",
    "        Returns:\n",
    "        Final text answer from the LLM, given the relevant documents.\n",
    "    \"\"\"\n",
    "    query_vector = get_embedding(query)\n",
    "    \n",
    "    results = index.query(\n",
    "        vector = query_vector,\n",
    "        top_k = 10,\n",
    "        include_values = False,\n",
    "        include_metadata = True,\n",
    "        filter={\n",
    "            \"ADMIN_ID\" : os.getenv('ADMIN_ID_QA'),\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    relevant_pairs = []\n",
    "    for record in results['matches']:\n",
    "        pair = {}\n",
    "        pair['id'] = record['metadata']['QA_ID']\n",
    "        pair['score'] = record['score']\n",
    "        pair['question'] = record['metadata']['question']\n",
    "        pair['answer'] = record['metadata']['answer']\n",
    "        relevant_pairs.append(pair)\n",
    "    \n",
    "    \n",
    "    final_prompt = query_prompt.invoke({\"query\" : query,\"documents\": relevant_pairs}).text\n",
    "    return fetch_answer(final_prompt)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the tool ready, we will be making the prompt for the agent. This aims to clearly tell the assisant what has to be done and what is the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an assistant who can handle queries by using the tool you have and refer the user to correct question answer pairs, you just have to pass the exact user query to the tool and it will do the rest, and just give them the answer as it has come from the tool...\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now initialise the LLM instance from langchain and then use the tools above and bind them to the agent, which would be used to fetch the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key = OPENAI_API_KEY,\n",
    "    model = \"gpt-4o\",\n",
    "    temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [answer_query]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this function creates an agent pipeline in a step-by-step flow, processing input data and returning a meaningful output. How the Pipeline Works Together : \n",
    "- Input Preparation: The user’s query (x[\"input\"]) and intermediate steps are extracted and formatted.\n",
    "- Main Prompt Application: The instructions for the agent (e.g., \"You are a helpful assistant\") are added to guide its behavior.\n",
    "- Processing by LLM: The LLM processes the input and, if needed, interacts with tools to generate an appropriate response.\n",
    "- Output Parsing: The raw response from the LLM is cleaned up for easy understanding by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | main_prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can execute the function and see how the agent works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new None chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `answer_query` with `{'query': 'I was having issues in my NEXTJS project, as I tried to animate the dropdown menu, I got a hydration error.'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mTo address the hydration error you are experiencing in your Next.js project while trying to animate a dropdown menu, you can follow these steps:\n",
      "\n",
      "1. **Restart the Server**: Sometimes, simply restarting the server can resolve hydration issues.\n",
      "   \n",
      "2. **Inspect Styles**: Use the browser's inspect element tool to check if Tailwind CSS is being loaded correctly. If the styles are visible in the inspector but not applied, it might indicate a configuration issue with Tailwind CSS.\n",
      "\n",
      "3. **Verify Tailwind Configuration**: Ensure that your Tailwind CSS setup is correct. This involves checking your Tailwind configuration file to make sure the necessary classes are being generated and applied.\n",
      "\n",
      "For more detailed guidance, you can refer to the conversation with the ID `9cef8bde-c6a7-4758-a736-7d2097c0b38a` where a similar issue was discussed. Exploring that thread might provide additional insights and solutions specific to your problem.\u001b[0m\u001b[32;1m\u001b[1;3mTo resolve the hydration error in your Next.js project when animating a dropdown menu, try the following steps:\n",
      "\n",
      "1. **Restart the Server**: Sometimes, restarting the server can fix hydration issues.\n",
      "\n",
      "2. **Inspect Styles**: Use the browser's inspect tool to check if Tailwind CSS is loading correctly. If styles are visible in the inspector but not applied, there might be a configuration issue.\n",
      "\n",
      "3. **Verify Tailwind Configuration**: Ensure your Tailwind CSS setup is correct by checking your configuration file to make sure necessary classes are generated and applied.\n",
      "\n",
      "For more detailed guidance, refer to the conversation with ID `9cef8bde-c6a7-4758-a736-7d2097c0b38a`, where a similar issue was discussed. This might provide additional insights specific to your problem.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'actions': [ToolAgentAction(tool='answer_query', tool_input={'query': 'I was having issues in my NEXTJS project, as I tried to animate the dropdown menu, I got a hydration error.'}, log=\"\\nInvoking: `answer_query` with `{'query': 'I was having issues in my NEXTJS project, as I tried to animate the dropdown menu, I got a hydration error.'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_G4PYX3mACnDphE6SZ2CebMip', 'function': {'arguments': '{\"query\":\"I was having issues in my NEXTJS project, as I tried to animate the dropdown menu, I got a hydration error.\"}', 'name': 'answer_query'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4'}, id='run-aa1bae58-c543-40b1-9f87-a5fe7f298a0f', tool_calls=[{'name': 'answer_query', 'args': {'query': 'I was having issues in my NEXTJS project, as I tried to animate the dropdown menu, I got a hydration error.'}, 'id': 'call_G4PYX3mACnDphE6SZ2CebMip', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'answer_query', 'args': '{\"query\":\"I was having issues in my NEXTJS project, as I tried to animate the dropdown menu, I got a hydration error.\"}', 'id': 'call_G4PYX3mACnDphE6SZ2CebMip', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_G4PYX3mACnDphE6SZ2CebMip')],\n",
       "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_G4PYX3mACnDphE6SZ2CebMip', 'function': {'arguments': '{\"query\":\"I was having issues in my NEXTJS project, as I tried to animate the dropdown menu, I got a hydration error.\"}', 'name': 'answer_query'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4'}, id='run-aa1bae58-c543-40b1-9f87-a5fe7f298a0f', tool_calls=[{'name': 'answer_query', 'args': {'query': 'I was having issues in my NEXTJS project, as I tried to animate the dropdown menu, I got a hydration error.'}, 'id': 'call_G4PYX3mACnDphE6SZ2CebMip', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'answer_query', 'args': '{\"query\":\"I was having issues in my NEXTJS project, as I tried to animate the dropdown menu, I got a hydration error.\"}', 'id': 'call_G4PYX3mACnDphE6SZ2CebMip', 'index': 0, 'type': 'tool_call_chunk'}])]},\n",
       " {'steps': [AgentStep(action=ToolAgentAction(tool='answer_query', tool_input={'query': 'I was having issues in my NEXTJS project, as I tried to animate the dropdown menu, I got a hydration error.'}, log=\"\\nInvoking: `answer_query` with `{'query': 'I was having issues in my NEXTJS project, as I tried to animate the dropdown menu, I got a hydration error.'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_G4PYX3mACnDphE6SZ2CebMip', 'function': {'arguments': '{\"query\":\"I was having issues in my NEXTJS project, as I tried to animate the dropdown menu, I got a hydration error.\"}', 'name': 'answer_query'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4'}, id='run-aa1bae58-c543-40b1-9f87-a5fe7f298a0f', tool_calls=[{'name': 'answer_query', 'args': {'query': 'I was having issues in my NEXTJS project, as I tried to animate the dropdown menu, I got a hydration error.'}, 'id': 'call_G4PYX3mACnDphE6SZ2CebMip', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'answer_query', 'args': '{\"query\":\"I was having issues in my NEXTJS project, as I tried to animate the dropdown menu, I got a hydration error.\"}', 'id': 'call_G4PYX3mACnDphE6SZ2CebMip', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_G4PYX3mACnDphE6SZ2CebMip'), observation=\"To address the hydration error you are experiencing in your Next.js project while trying to animate a dropdown menu, you can follow these steps:\\n\\n1. **Restart the Server**: Sometimes, simply restarting the server can resolve hydration issues.\\n   \\n2. **Inspect Styles**: Use the browser's inspect element tool to check if Tailwind CSS is being loaded correctly. If the styles are visible in the inspector but not applied, it might indicate a configuration issue with Tailwind CSS.\\n\\n3. **Verify Tailwind Configuration**: Ensure that your Tailwind CSS setup is correct. This involves checking your Tailwind configuration file to make sure the necessary classes are being generated and applied.\\n\\nFor more detailed guidance, you can refer to the conversation with the ID `9cef8bde-c6a7-4758-a736-7d2097c0b38a` where a similar issue was discussed. Exploring that thread might provide additional insights and solutions specific to your problem.\")],\n",
       "  'messages': [FunctionMessage(content=\"To address the hydration error you are experiencing in your Next.js project while trying to animate a dropdown menu, you can follow these steps:\\n\\n1. **Restart the Server**: Sometimes, simply restarting the server can resolve hydration issues.\\n   \\n2. **Inspect Styles**: Use the browser's inspect element tool to check if Tailwind CSS is being loaded correctly. If the styles are visible in the inspector but not applied, it might indicate a configuration issue with Tailwind CSS.\\n\\n3. **Verify Tailwind Configuration**: Ensure that your Tailwind CSS setup is correct. This involves checking your Tailwind configuration file to make sure the necessary classes are being generated and applied.\\n\\nFor more detailed guidance, you can refer to the conversation with the ID `9cef8bde-c6a7-4758-a736-7d2097c0b38a` where a similar issue was discussed. Exploring that thread might provide additional insights and solutions specific to your problem.\", additional_kwargs={}, response_metadata={}, name='answer_query')]},\n",
       " {'output': \"To resolve the hydration error in your Next.js project when animating a dropdown menu, try the following steps:\\n\\n1. **Restart the Server**: Sometimes, restarting the server can fix hydration issues.\\n\\n2. **Inspect Styles**: Use the browser's inspect tool to check if Tailwind CSS is loading correctly. If styles are visible in the inspector but not applied, there might be a configuration issue.\\n\\n3. **Verify Tailwind Configuration**: Ensure your Tailwind CSS setup is correct by checking your configuration file to make sure necessary classes are generated and applied.\\n\\nFor more detailed guidance, refer to the conversation with ID `9cef8bde-c6a7-4758-a736-7d2097c0b38a`, where a similar issue was discussed. This might provide additional insights specific to your problem.\",\n",
       "  'messages': [AIMessage(content=\"To resolve the hydration error in your Next.js project when animating a dropdown menu, try the following steps:\\n\\n1. **Restart the Server**: Sometimes, restarting the server can fix hydration issues.\\n\\n2. **Inspect Styles**: Use the browser's inspect tool to check if Tailwind CSS is loading correctly. If styles are visible in the inspector but not applied, there might be a configuration issue.\\n\\n3. **Verify Tailwind Configuration**: Ensure your Tailwind CSS setup is correct by checking your configuration file to make sure necessary classes are generated and applied.\\n\\nFor more detailed guidance, refer to the conversation with ID `9cef8bde-c6a7-4758-a736-7d2097c0b38a`, where a similar issue was discussed. This might provide additional insights specific to your problem.\", additional_kwargs={}, response_metadata={})]}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "list(agent_executor.stream({\"input\": \"I was having issues in my NEXTJS project, as I tried to animate the dropdown menu, I got a hydration error.\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new None chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `answer_query` with `{'query': 'how JWT works'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mA JWT (JSON Web Token) works by taking a string and converting it into a token that can be used for authentication. The key plays a crucial role in signing and verifying the token, ensuring that it hasn't been tampered with. It does not encrypt or decrypt the token but is used to sign the token on the server side. The JWT consists of three parts: the payload, the secret key, and the expiry time. The secret key is essential for the server to verify the authenticity of the token sent by the client. If the token is valid, the server allows the client to proceed with further activities.\n",
      "\n",
      "For more detailed information, you can refer to the conversation with the ID `2cef8bde-d6a7-4758-a736-7d2097c0b38a`. Exploring that thread might provide additional insights into how JWTs work and their implementation.\u001b[0m\u001b[32;1m\u001b[1;3mA JWT (JSON Web Token) works by taking a string and converting it into a token that can be used for authentication. The key plays a crucial role in signing and verifying the token, ensuring that it hasn't been tampered with. It does not encrypt or decrypt the token but is used to sign the token on the server side. The JWT consists of three parts: the payload, the secret key, and the expiry time. The secret key is essential for the server to verify the authenticity of the token sent by the client. If the token is valid, the server allows the client to proceed with further activities.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'actions': [ToolAgentAction(tool='answer_query', tool_input={'query': 'how JWT works'}, log=\"\\nInvoking: `answer_query` with `{'query': 'how JWT works'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_1n7fzb8WW0plzZh00iIfyOeM', 'function': {'arguments': '{\"query\":\"how JWT works\"}', 'name': 'answer_query'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4'}, id='run-a8d637e7-115f-42b4-a82f-2ef10c601d6f', tool_calls=[{'name': 'answer_query', 'args': {'query': 'how JWT works'}, 'id': 'call_1n7fzb8WW0plzZh00iIfyOeM', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'answer_query', 'args': '{\"query\":\"how JWT works\"}', 'id': 'call_1n7fzb8WW0plzZh00iIfyOeM', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_1n7fzb8WW0plzZh00iIfyOeM')],\n",
       "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_1n7fzb8WW0plzZh00iIfyOeM', 'function': {'arguments': '{\"query\":\"how JWT works\"}', 'name': 'answer_query'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4'}, id='run-a8d637e7-115f-42b4-a82f-2ef10c601d6f', tool_calls=[{'name': 'answer_query', 'args': {'query': 'how JWT works'}, 'id': 'call_1n7fzb8WW0plzZh00iIfyOeM', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'answer_query', 'args': '{\"query\":\"how JWT works\"}', 'id': 'call_1n7fzb8WW0plzZh00iIfyOeM', 'index': 0, 'type': 'tool_call_chunk'}])]},\n",
       " {'steps': [AgentStep(action=ToolAgentAction(tool='answer_query', tool_input={'query': 'how JWT works'}, log=\"\\nInvoking: `answer_query` with `{'query': 'how JWT works'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_1n7fzb8WW0plzZh00iIfyOeM', 'function': {'arguments': '{\"query\":\"how JWT works\"}', 'name': 'answer_query'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4'}, id='run-a8d637e7-115f-42b4-a82f-2ef10c601d6f', tool_calls=[{'name': 'answer_query', 'args': {'query': 'how JWT works'}, 'id': 'call_1n7fzb8WW0plzZh00iIfyOeM', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'answer_query', 'args': '{\"query\":\"how JWT works\"}', 'id': 'call_1n7fzb8WW0plzZh00iIfyOeM', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_1n7fzb8WW0plzZh00iIfyOeM'), observation=\"A JWT (JSON Web Token) works by taking a string and converting it into a token that can be used for authentication. The key plays a crucial role in signing and verifying the token, ensuring that it hasn't been tampered with. It does not encrypt or decrypt the token but is used to sign the token on the server side. The JWT consists of three parts: the payload, the secret key, and the expiry time. The secret key is essential for the server to verify the authenticity of the token sent by the client. If the token is valid, the server allows the client to proceed with further activities.\\n\\nFor more detailed information, you can refer to the conversation with the ID `2cef8bde-d6a7-4758-a736-7d2097c0b38a`. Exploring that thread might provide additional insights into how JWTs work and their implementation.\")],\n",
       "  'messages': [FunctionMessage(content=\"A JWT (JSON Web Token) works by taking a string and converting it into a token that can be used for authentication. The key plays a crucial role in signing and verifying the token, ensuring that it hasn't been tampered with. It does not encrypt or decrypt the token but is used to sign the token on the server side. The JWT consists of three parts: the payload, the secret key, and the expiry time. The secret key is essential for the server to verify the authenticity of the token sent by the client. If the token is valid, the server allows the client to proceed with further activities.\\n\\nFor more detailed information, you can refer to the conversation with the ID `2cef8bde-d6a7-4758-a736-7d2097c0b38a`. Exploring that thread might provide additional insights into how JWTs work and their implementation.\", additional_kwargs={}, response_metadata={}, name='answer_query')]},\n",
       " {'output': \"A JWT (JSON Web Token) works by taking a string and converting it into a token that can be used for authentication. The key plays a crucial role in signing and verifying the token, ensuring that it hasn't been tampered with. It does not encrypt or decrypt the token but is used to sign the token on the server side. The JWT consists of three parts: the payload, the secret key, and the expiry time. The secret key is essential for the server to verify the authenticity of the token sent by the client. If the token is valid, the server allows the client to proceed with further activities.\",\n",
       "  'messages': [AIMessage(content=\"A JWT (JSON Web Token) works by taking a string and converting it into a token that can be used for authentication. The key plays a crucial role in signing and verifying the token, ensuring that it hasn't been tampered with. It does not encrypt or decrypt the token but is used to sign the token on the server side. The JWT consists of three parts: the payload, the secret key, and the expiry time. The secret key is essential for the server to verify the authenticity of the token sent by the client. If the token is valid, the server allows the client to proceed with further activities.\", additional_kwargs={}, response_metadata={})]}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "list(agent_executor.stream({\"input\": \"I am so confused about how JWT works...\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we now have an agent which will be answering the core question asked by the user, based on the Q&A knowledge base. We can replicate the same for text knowledge base query, as that has a different type of dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
