{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate \n",
    "import pandas as pd\n",
    "import json\n",
    "import markdown\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_API_ENV = os.getenv(\"PINECONE_API_ENV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data \n",
    "Now, each conversation is stored as a chat history json (assumig similar structure from Discord API), where each key is the name of the user and the value is the message sent by user, and this flow is maintained in the conversation. Now, our aim is to load these into the format we want to store as a vector. For now, let us store the conversation as a list of jsons, where each json is a chat history of a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = [\n",
    "    {\n",
    "    \"Dalvi OP\": \"i am currently doing the Excalidraw Project i was watching the second video i created all the files and followed all the steps but when i am executing the code by pnpm run dev i am getting this error i am stuck in this error for 3 hours if someone can please help me solve this error it would be very helpful for me\",\n",
    "    \"TA Tarun\": \"what is the error?\",\n",
    "    \"Dalvi OP (later)\": \"??\",\n",
    "    \"TA Tarun (later)\": \"are you using esbuild?\",\n",
    "    \"Dalvi OP (response)\": \"I don't think so where should I check if I am using it or no\",\n",
    "    \"TA Harry Potter\": \"You need to configure it inside the http-backend app\",\n",
    "    \"TA Tarun (later)\": \"package.json of http-server\",\n",
    "    \"TA Sumana\": \"use latest version of node\",\n",
    "    \"Dalvi OP (response final)\": \"@TA Sumana @TA Tarun @TA Harry Potter thankyou all of you the issue is resolved :perfect:\"\n",
    "  },\n",
    "  {\n",
    "    \"Samim Rezvi OP\": \"how does a jwt work...like it takes a string and converts it into something random...what is the role of key here? @TA Harry Potter @TA Sumana @TA SerBarristan\",\n",
    "    \"TA Harry Potter\": \"google kiya?\",\n",
    "    \"Samim Rezvi OP (response)\": \"yes key ka role samajh nhi aya\",\n",
    "    \"TA Harry Potter (clarification)\": \"it's that, allows verification that the token wasn't tampered with.\",\n",
    "    \"Samim Rezvi OP (clarification request)\": \"mtlb key encrypt and decrypt krta hai na?\",\n",
    "    \"TA Harry Potter (clarification final)\": \"Nahi, JWT ke case mein key encrypt aur decrypt nahi karti, balki sign aur verify karne ke liye use hoti hai.\",\n",
    "    \"akshiiittt\": \"Basically jwt authentication mein kaam aati hai, like vo ek random kuch text generate karta hai jisko ham sign ki madad se create karte hai jismein ham 3 values pass on krte, first one is the payload second is the secret key(jo sabse main hai jiski help se hi server verfiy kar pata hai ki ki jwt jo genrate hua hai voh sahi hai ya galat and third pe expiry time of that token). This is basically the main thing of the jwt and second verify hota hai jo client se send hota hai and server compare karta hai secret ki help se yeh sahi token hai ke nahi and then hi allow karta hai client ko aggey kuch bhi activities karne ke liye.\",\n",
    "    \"Samim Rezvi OP (final)\": \"accha...samajh gya.... thanks man\"\n",
    "  },\n",
    "  {\n",
    "    \"Shubha Sarkar OP\": \"I am struggling a lot when building the second brain app using Recoil. Fetch all data when the /dashboard component loads from backend show in UI. There are 3 endpoints in backend \\\"/create\\\" \\\"/edit:id\\\" \\\"/delete:id\\\". The UI should update immediately and also update in backend when user performs these operations.\",\n",
    "    \"TA Harry Potter\": \"Screen recording of the issue?\",\n",
    "    \"Shubha Sarkar OP (response)\": \"https://drive.google.com/drive/folders/1e1n6mXUls2DD6yxnPANFfnEMKiJgeznd?usp=sharing\",\n",
    "    \"TA Harry Potter (later)\": \"I'll check. Outside my home rn\",\n",
    "    \"TA Harry Potter (recommendation)\": \"You should use an atom for state storage and combine it with a useEffect to fetch initial data on /dashboard load. It ensures updates reflect instantly by modifying the atom after every operation.\"\n",
    "  },\n",
    "  {\n",
    "    \"TANAY\": \"I am creating a project in NextJs. It was running fine but suddenly an error occurred while trying to animate the dropdown menu. Then I don't know why hydration error occurred. An error in global.css happened. When I undid the changes and re-ran the server, the error was gone but my styles were also gone.\",\n",
    "    \"TA Jack Sparrow\": \"Restart the server and try again. Also inspect the styles like if Tailwind is even working or not.\",\n",
    "    \"TANAY (response)\": \"It is showing but not applied.\",\n",
    "    \"TA Jack Sparrow (clarification)\": \"Check the style in inspect elements.\",\n",
    "    \"TANAY (clarification request)\": \"Also now it is showing hydration error.\",\n",
    "    \"TA Jack Sparrow (suggestion)\": \"Check Tailwind docs to set it up again.\"\n",
    "  },\n",
    "  {\n",
    "    \"Aniket\": \"Auth.tsx\\nimport { useRef } from \\\"react\\\";\\nimport { Button } from \\\"../components/Button\\\";\\nimport { Input } from \\\"../components/Input\\\";\\nimport { BACKEND_URL } from \\\"../../config\\\";\\nimport axios from \\\"axios\\\";\\n\\nexport const Signup = () => {\\n const usernameRef = useRef<HTMLInputElement>();\\n const passwordRef = useRef<HTMLInputElement>();\\n\\n const handleSignup = async () => {\\n try {\\n const username = usernameRef.current?.value;\\n // console.log(username)\\n const password = passwordRef.current?.value;\\n // console.log(password)\\n\\n await axios.post(BACKEND_URL + \\\"/api/v1/signup\\\", {\\n username,\\n password\\n });\\n } catch (error) {\\n console.log(error);\\n }\\n alert(\\\"User signed up!\\\");\\n };\\n\\n return (\\n <div className=\\\"flex justify-center items-center h-screen w-screen bg-gray-200\\\">\\n <div className=\\\"bg-white rounded-md min-w-48 flex items-center justify-center flex-col p-8\\\">\\n <Input reference={usernameRef} type=\\\"text\\\" placeholder=\\\"Username\\\" />\\n <Input reference={passwordRef} type=\\\"password\\\" placeholder=\\\"Password\\\" />\\n <div className=\\\"w-full mt-4\\\">\\n <Button\\n variant=\\\"primary\\\"\\n size=\\\"md\\\"\\n text=\\\"Signup\\\"\\n fullWidth={true}\\n onClick={handleSignup}\\n />\\n </div>\\n </div>\\n </div>\\n );\\n};\\n\\nexport const Signin = () => {\\n return (\\n <div className=\\\"flex justify-center items-center h-screen w-screen bg-gray-200\\\">\\n <div className=\\\"bg-white rounded-md min-w-48 flex items-center justify-center flex-col p-8\\\">\\n <Input type=\\\"text\\\" placeholder=\\\"Username\\\" />\\n <Input type=\\\"password\\\" placeholder=\\\"Password\\\" />\\n <div className=\\\"w-full mt-4\\\">\\n <Button variant=\\\"primary\\\" size=\\\"md\\\" text=\\\"Signin\\\" fullWidth={true} />\\n </div>\\n </div>\\n </div>\\n );\\n};\",\n",
    "    \"Aniket (mention)\": \"@TA (WebDev and Devops)\",\n",
    "    \"TA Harry Potter\": \"did you test the api in postman?\",\n",
    "    \"TA Tarun\": \"add origin: * inside cors()\",\n",
    "    \"Aniket (response)\": \"Yes\",\n",
    "    \"Aniket (try)\": \"Ok let me try\",\n",
    "    \"TA Harry Potter (advice)\": \"then enable it for the FE origin\\n\\napp.use(cors({\\n origin: process.env.FRONTEND_URL || \\\"http://localhost:5173\\\",\\n methods: ['GET', 'POST', 'PUT', 'DELETE'],\\n credentials: true\\n}));\\nif you wanna enable for all origin\",\n",
    "    \"TA Harry Potter (repeat)\": \"tarun add origin: \",\n",
    "    \"Aniket\": \"Updated the code still doesn't work\",\n",
    "    \"TA Harry Potter\": \"app.use(cors(\\\"\\\")) this?\",\n",
    "    \"Aniket\": \"you mean app.use(cors({\\n origin: \\\"*\\\",\\n})) ?\",\n",
    "    \"TA Harry Potter (confirmation)\": \"yeah\",\n",
    "    \"Aniket\": \"No\",\n",
    "    \"TA Harry Potter (question)\": \"did you rebuild the server?\",\n",
    "    \"Aniket\": \"Yes I did\",\n",
    "    \"TA Harry Potter (suggestion)\": \"try logging the inputs in server routes and see if you are getting right or not\",\n",
    "    \"Crytek\": \"reinstall the cors and re-import the cors module\",\n",
    "    \"Aniket (resolved)\": \"The issue is resolved now ðŸŽ‰. I noticed that whenever I add \\\"return\\\" statement it gave me this error. When I removed the return statement, it worked. Can anyone explain this why\"\n",
    "  },\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Assistant Inferencing\n",
    "Now, we have designed an assistant in openAI which will assist to summarise these chats and get them as valid json Q&A pairs. Below, we can see the process of inferencing the assistant and fetching the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openAI_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "assistant_id = os.getenv(\"QA_SUMMARISER_OPENAI_ASSISTANT_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to create a thread. A thread here represents a conversation between a user and an assistant. Along with that, we should also sequentially add the messages from the conversation list to the thread. So here, the catch is that we will have to initiate a thread, add a conversation as the first message from the user, and then run the thread with the assistant. The assistant will then respond to the user's message and will add it's response as the next message in the thread. \n",
    "\n",
    "Since this has to be done sequentially, we will have to run the assistant for each conversation in the list and develop the functionalities in a modular way to be used later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = openAI_client.beta.threads.create()\n",
    "\n",
    "def create_QAPair(conversation):\n",
    "    openAI_client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content= [{\n",
    "            \"type\" : \"text\",\n",
    "            \"text\" : json.dumps(conversation)\n",
    "        }]\n",
    "    )\n",
    "            \n",
    "    run = openAI_client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant_id,\n",
    "    )\n",
    "    \n",
    "    return run\n",
    "\n",
    "def get_QAPair(thread, run):\n",
    "    while True:\n",
    "        run = openAI_client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "        if run.status == 'completed':\n",
    "            messages = openAI_client.beta.threads.messages.list(\n",
    "                thread_id=thread.id\n",
    "            )\n",
    "            return messages\n",
    "        elif run.status in ['failed', 'cancelled', 'expired']:\n",
    "            raise Exception(f\"Run ended with status: {run.status}\")\n",
    "        time.sleep(1)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us run the thread individually for each conversation, get the output and append it to the list of outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_QAs(conversations):\n",
    "    QAs = []\n",
    "    for conversation in conversations : \n",
    "        run = create_QAPair(conversation)\n",
    "        messages = get_QAPair(thread, run)\n",
    "        if(messages):\n",
    "            QAs.append(messages.data[0].content[0].text.value)\n",
    "        else:\n",
    "            QAs.append({\"question\" : \"Not available\", \"answer\" : \"Not available\"})\n",
    "    return QAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "QAs_PreID = get_QAs(conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"question\":\"A person is facing an error while executing code for the Excalidraw Project using \\'pnpm run dev\\' and has been stuck for several hours. They are unsure if they are using \\'package.json\\' of \\'http-server\\'.\",\"answer\":\"The error was resolved by configuring the \\'http-backend app\\' and ensuring the use of the latest version of Node.js. Assistance from multiple sources helped in identifying and fixing the issue.\"}',\n",
       " '{\"question\":\"How does a JWT (JSON Web Token) work, particularly the role of the key in JWT?\",\"answer\":\"A JWT works by taking a string and converting it into a token that can be used for authentication. The key in JWT is not used for encryption and decryption but for signing and verifying the token. The JWT consists of three parts: the payload, the secret key, and the expiry time. The secret key is crucial as it allows the server to verify that the token was not tampered with and is valid. When a client sends a JWT, the server uses the secret key to verify the token\\'s authenticity before allowing the client to perform any further actions.\"}',\n",
       " '{\"question\":\"How can one build a second brain app using Recoil to fetch all data when the /dashboard component loads, and ensure the UI updates immediately and reflects changes in the backend when using endpoints \\\\\"/create\\\\\", \\\\\"/edit:id\\\\\", and \\\\\"/delete:id\\\\\"?\",\"answer\":\"To build the app using Recoil, one should use an atom for state storage and combine it with a useEffect hook to fetch initial data when the /dashboard component loads. This setup ensures that updates are reflected instantly in the UI by modifying the atom after every operation such as create, edit, or delete. This approach helps in synchronizing the UI with the backend effectively.\"}',\n",
       " '{\"question\":\"While creating a project in Next.js, a person encountered a hydration error and styling issues after attempting to animate a dropdown menu. The error disappeared after undoing changes, but the styles were also removed. How can this issue be resolved?\",\"answer\":\"To resolve the issue, restart the server and inspect the styles to ensure Tailwind CSS is functioning correctly. If styles are not applied, check the elements in the browser\\'s inspect tool to verify if the styles are being loaded. If a hydration error persists, consult the Tailwind CSS documentation to ensure it is set up correctly in the project. This may involve reconfiguring Tailwind CSS to ensure it integrates properly with Next.js.\"}',\n",
       " '{\"question\":\"A person encountered an issue with CORS configuration in their application. They tried using \\'app.use(cors())\\' and adding \\'origin: *\\' inside \\'cors()\\'. The issue was resolved by removing a \\'return\\' statement, but they seek an explanation for why this resolved the issue.\",\"answer\":\"The initial CORS configuration was adjusted to enable it for the frontend origin using \\'app.use(cors({ origin: process.env.FRONTEND_URL || \\\\\"http://localhost:5173\\\\\", methods: [\\'GET\\', \\'POST\\', \\'PUT\\', \\'DELETE\\'], credentials: true }));\\'. This setup allows requests from the specified frontend URL. The issue was resolved by removing a \\'return\\' statement, which likely caused the middleware to exit prematurely, preventing the CORS headers from being properly set. Removing the \\'return\\' statement allowed the middleware to execute fully, thus resolving the error.\"}']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QAs_PreID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us mark each QA with a QA id for later purposes, for this we will use dummy QA id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2cef8bde-c6a7-4758-a736-7d2097c0b38a': '{\"question\":\"A person is facing an error while executing code for the Excalidraw Project using \\'pnpm run dev\\' and has been stuck for several hours. They are unsure if they are using \\'package.json\\' of \\'http-server\\'.\",\"answer\":\"The error was resolved by configuring the \\'http-backend app\\' and ensuring the use of the latest version of Node.js. Assistance from multiple sources helped in identifying and fixing the issue.\"}',\n",
       " '2cef8bde-d6a7-4758-a736-7d2097c0b38a': '{\"question\":\"How does a JWT (JSON Web Token) work, particularly the role of the key in JWT?\",\"answer\":\"A JWT works by taking a string and converting it into a token that can be used for authentication. The key in JWT is not used for encryption and decryption but for signing and verifying the token. The JWT consists of three parts: the payload, the secret key, and the expiry time. The secret key is crucial as it allows the server to verify that the token was not tampered with and is valid. When a client sends a JWT, the server uses the secret key to verify the token\\'s authenticity before allowing the client to perform any further actions.\"}',\n",
       " '2cef8bde-c6a7-4758-b736-7d2097c0b38a': '{\"question\":\"How can one build a second brain app using Recoil to fetch all data when the /dashboard component loads, and ensure the UI updates immediately and reflects changes in the backend when using endpoints \\\\\"/create\\\\\", \\\\\"/edit:id\\\\\", and \\\\\"/delete:id\\\\\"?\",\"answer\":\"To build the app using Recoil, one should use an atom for state storage and combine it with a useEffect hook to fetch initial data when the /dashboard component loads. This setup ensures that updates are reflected instantly in the UI by modifying the atom after every operation such as create, edit, or delete. This approach helps in synchronizing the UI with the backend effectively.\"}',\n",
       " '9cef8bde-c6a7-4758-a736-7d2097c0b38a': '{\"question\":\"While creating a project in Next.js, a person encountered a hydration error and styling issues after attempting to animate a dropdown menu. The error disappeared after undoing changes, but the styles were also removed. How can this issue be resolved?\",\"answer\":\"To resolve the issue, restart the server and inspect the styles to ensure Tailwind CSS is functioning correctly. If styles are not applied, check the elements in the browser\\'s inspect tool to verify if the styles are being loaded. If a hydration error persists, consult the Tailwind CSS documentation to ensure it is set up correctly in the project. This may involve reconfiguring Tailwind CSS to ensure it integrates properly with Next.js.\"}',\n",
       " '2cef8bde-c6a7-4758-a836-7d2097c0b38a': '{\"question\":\"A person encountered an issue with CORS configuration in their application. They tried using \\'app.use(cors())\\' and adding \\'origin: *\\' inside \\'cors()\\'. The issue was resolved by removing a \\'return\\' statement, but they seek an explanation for why this resolved the issue.\",\"answer\":\"The initial CORS configuration was adjusted to enable it for the frontend origin using \\'app.use(cors({ origin: process.env.FRONTEND_URL || \\\\\"http://localhost:5173\\\\\", methods: [\\'GET\\', \\'POST\\', \\'PUT\\', \\'DELETE\\'], credentials: true }));\\'. This setup allows requests from the specified frontend URL. The issue was resolved by removing a \\'return\\' statement, which likely caused the middleware to exit prematurely, preventing the CORS headers from being properly set. Removing the \\'return\\' statement allowed the middleware to execute fully, thus resolving the error.\"}'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_ID = [\"2cef8bde-c6a7-4758-a736-7d2097c0b38a\",\"2cef8bde-d6a7-4758-a736-7d2097c0b38a\",\"2cef8bde-c6a7-4758-b736-7d2097c0b38a\",\"9cef8bde-c6a7-4758-a736-7d2097c0b38a\",\"2cef8bde-c6a7-4758-a836-7d2097c0b38a\"]\n",
    "\n",
    "QAs = {}\n",
    "id = 0\n",
    "for QA in QAs_PreID:\n",
    "    QAs[QA_ID[id]] = QA\n",
    "    \n",
    "    id += 1\n",
    "\n",
    "QAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone Initialization\n",
    "Now, we will be using the pinecone vectorDB to store the embeddings of the QA Pairs. We will be using the `pinecone.init()` function to initialize the pinecone environment. We will be using the `pinecone.use_index()` function to use the index created for this project and setup the instance for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key = PINECONE_API_KEY, environment = PINECONE_API_ENV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us view the indexs avaliable in the pinecone environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexes': [{'deletion_protection': 'disabled',\n",
       "              'dimension': 1536,\n",
       "              'host': 'documents-hjunc2h.svc.aped-4627-b74a.pinecone.io',\n",
       "              'metric': 'cosine',\n",
       "              'name': 'documents',\n",
       "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
       "              'status': {'ready': True, 'state': 'Ready'},\n",
       "              'tags': {'embedding_model': 'text-embedding-3-small'},\n",
       "              'vector_type': 'dense'},\n",
       "             {'deletion_protection': 'disabled',\n",
       "              'dimension': 1536,\n",
       "              'host': 'qa-pairs-hjunc2h.svc.aped-4627-b74a.pinecone.io',\n",
       "              'metric': 'cosine',\n",
       "              'name': 'qa-pairs',\n",
       "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
       "              'status': {'ready': True, 'state': 'Ready'},\n",
       "              'tags': {'embedding_model': 'text-embedding-3-small'},\n",
       "              'vector_type': 'dense'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here, we will be using the index named `qa-pairs` to store the embeddings of the QA Pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding the Chunks using OpenAI text-embedding-3-small\n",
    "Here, we will be using the OpenAI text-embedding-3-small model to embed the chunks, for which we will need an openAI instance initialised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "openAI_embedding_client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us go ahead and set the embeddings model and a function to get the embeddings of any given text via the text-embedding-3-small model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = openAI_client.embeddings\n",
    "\n",
    "def get_embedding(text) :\n",
    "    response = embedding_model.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "Now that we have the Q&A pairs, we can store them as vectors in pinecone and use them for similarity search. We can use the `pinecone` library to store the vectors in the pinecone database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, each Q&A pair will belong to a course, where we will be having the : \n",
    " \n",
    "- Admin ID\n",
    "- Course ID\n",
    "- Topic ID\n",
    "- Q&A Pair ID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the ID for each vector will be in the format `admin-id_course-id_topic-id_QA-id` so that each pair can be searched and retrieved easily. Although searching is done via metadata filters, we create this uniuqe ID for each vector for easy deletion and retrieval.\n",
    "\n",
    "Also, each pair will be stored in database.To simiplify the process, each entry in the vectorDB should have : \n",
    "\n",
    "* **ID** : The unique ID of the document, which will be a combination of the admin id, course id, topic id and QA id.\n",
    "* **VALUES** : The embedding of the question and answer pair, as generated by the OpenAI text-embedding-3-small model.\n",
    "* **METADATA** : The metadata of the document, which will include as follows : \n",
    "    *  **ADMIN_ID** : The ID of the admin in our system.\n",
    "    *  **COURSE_ID** : The ID of the course in our system.\n",
    "    *  **TOPIC_ID** : The ID of the topic in our system (pre-defined by Admin)\n",
    "    *  **QA_ID** : The ID of the QA conversation in our system.\n",
    "    *  **QUESTION** : The question in the Q&A pair.\n",
    "    *  **ANSWER** : The answer in the Q&A pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADMIN_ID = \"d359d72b-40e8-4e9f-b567-62d77f273113\"\n",
    "COURSE_ID = \"d0305607-30cf-4dfb-ba84-5dc407d9d5bf\"\n",
    "TOPIC_ID = \"e766a834-d346-4265-8e5e-78e0832cabf0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now create the function to create vectors in our desired format as defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectors(QAs,ADMIN_ID,COURSE_ID,TOPIC_ID):\n",
    "    vectors = []\n",
    "    \n",
    "    for QA in QAs: \n",
    "        entry = {}\n",
    "        entry[\"id\"] = f\"{ADMIN_ID}_{COURSE_ID}_{TOPIC_ID}_{QA}\"\n",
    "        \n",
    "        question = json.loads(QAs[QA])[\"question\"]\n",
    "        answer = json.loads(QAs[QA])[\"answer\"]\n",
    "        text = \"Question : \" + question + \"\\nAnswer : \" + answer\n",
    "        \n",
    "        entry[\"values\"] = get_embedding(text)\n",
    "        entry[\"metadata\"] = {\n",
    "            \"ADMIN_ID\" : ADMIN_ID,\n",
    "            \"COURSE_ID\" : COURSE_ID,\n",
    "            \"TOPIC_ID\" : TOPIC_ID,\n",
    "            \"QA_ID\" : QA,\n",
    "            \"question\" : question,\n",
    "            \"answer\" : answer\n",
    "        }\n",
    "        \n",
    "        vectors.append(entry)\n",
    "        \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = create_vectors(QAs,ADMIN_ID,COURSE_ID,TOPIC_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we have our vectors stored in the ideal format to be pushed into the vector DB. Let us now push the vectors into the vectorDB of pinecone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pushing the Vectors into the Pinecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 5}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"qa-pairs\"\n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "index.upsert(\n",
    "    vectors=vectors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying the Vectors\n",
    "We shall now query the vectors to check if the vectors have been stored correctly in the pinecone index, and how does this exactly work. We will fetch the relevant vectors from the pinecone index. For that, we will create a function which takes a text query, converts into to an embedding and queries the pinecone index to get the most similar texts from the vectors stored in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_pairs(query,ADMIN_ID,COURSE_ID,TOPIC_ID):\n",
    "    query_vector = get_embedding(query)\n",
    "    \n",
    "    results = index.query(\n",
    "        vector = query_vector,\n",
    "        top_k = 10,\n",
    "        include_values = False,\n",
    "        include_metadata = True,\n",
    "        filter={\n",
    "            \"ADMIN_ID\" : ADMIN_ID,\n",
    "            \"COURSE_ID\" : COURSE_ID,\n",
    "            \"TOPIC_ID\" : TOPIC_ID,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    relevant_pairs = []\n",
    "    for record in results['matches']:\n",
    "        pair = {}\n",
    "        pair['id'] = record['metadata']['QA_ID']\n",
    "        pair['score'] = record['score']\n",
    "        pair['question'] = record['metadata']['question']\n",
    "        pair['answer'] = record['metadata']['answer']\n",
    "        relevant_pairs.append(pair)\n",
    "    \n",
    "    return relevant_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create a QA system which will take a query and return the most relevant chunks from the PDF document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0.532283187 \n",
      " Question How does a JWT work, and what is the role of the key in it? \n",
      " Answer: \n",
      " A JWT (JSON Web Token) works by taking a string and converting it into a token that can be used for authentication. The key plays a crucial role in signing and verifying the token, ensuring it hasn't been tampered with. The process involves creating a token with three parts: the payload, the secret key, and the expiry time. The secret key is essential for the server to verify the authenticity of the token sent by the client. It does not encrypt or decrypt the token but is used to sign and verify it, allowing the server to confirm the token's validity before permitting any client activities.\n",
      "------------------------\n",
      "Rank 0.214643821 \n",
      " Question I was facing an issue with CORS in my application, and it was resolved when I removed the 'return' statement. Can anyone explain why this happened? \n",
      " Answer: \n",
      " The issue with CORS was resolved by removing the 'return' statement because it might have been prematurely terminating the function, preventing the CORS configuration from being properly applied. When setting up CORS, it's important to ensure that the middleware is correctly configured and executed. By removing the 'return' statement, the function likely continued to execute as intended, allowing the CORS settings to be applied correctly. Additionally, ensuring that the server is rebuilt and logging inputs in server routes can help verify that the correct configurations are in place.\n",
      "------------------------\n",
      "Rank 0.170333564 \n",
      " Question I am facing a hydration error in my Next.js project after trying to animate a dropdown menu, and my styles are not being applied even though they are showing. How can I resolve this? \n",
      " Answer: \n",
      " To resolve the hydration error and styling issues in your Next.js project, first restart the server and inspect the styles using the browser's inspect element tool to ensure Tailwind CSS is being applied. If the styles are not applied, verify that Tailwind CSS is correctly set up by referring to the Tailwind documentation. Undoing changes might temporarily fix the error but can also remove styles, so ensure your Tailwind setup is correct and consistent with the documentation.\n",
      "------------------------\n",
      "Rank 0.125880882 \n",
      " Question How can I build a second brain app using Recoil to fetch all data when the /dashboard component loads and ensure the UI updates immediately with backend synchronization for create, edit, and delete operations? \n",
      " Answer: \n",
      " To build the second brain app using Recoil, you should use an atom to store the state of your data. Combine this with a useEffect hook to fetch the initial data from the backend when the /dashboard component loads. This setup will ensure that the UI updates immediately by modifying the atom whenever a user performs create, edit, or delete operations. The useEffect will handle the initial data fetch, and the atom will manage the state updates, ensuring synchronization with the backend.\n",
      "------------------------\n",
      "Rank 0.123841383 \n",
      " Question I am getting an error while executing the code for the Excalidraw Project using pnpm run dev. Can someone help me solve this error? \n",
      " Answer: \n",
      " The error was resolved by ensuring the correct configuration of the package.json file for the http-server and using the latest version of Node.js. The teaching assistants suggested checking the package.json configuration and updating Node.js, which helped in resolving the issue.\n",
      "------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Rank 0.360175699 \n",
      " Question I was facing an issue with CORS in my application, and it was resolved when I removed the 'return' statement. Can anyone explain why this happened? \n",
      " Answer: \n",
      " The issue with CORS was resolved by removing the 'return' statement because it might have been prematurely terminating the function, preventing the CORS configuration from being properly applied. When setting up CORS, it's important to ensure that the middleware is correctly configured and executed. By removing the 'return' statement, the function likely continued to execute as intended, allowing the CORS settings to be applied correctly. Additionally, ensuring that the server is rebuilt and logging inputs in server routes can help verify that the correct configurations are in place.\n",
      "------------------------\n",
      "Rank 0.358753949 \n",
      " Question I am getting an error while executing the code for the Excalidraw Project using pnpm run dev. Can someone help me solve this error? \n",
      " Answer: \n",
      " The error was resolved by ensuring the correct configuration of the package.json file for the http-server and using the latest version of Node.js. The teaching assistants suggested checking the package.json configuration and updating Node.js, which helped in resolving the issue.\n",
      "------------------------\n",
      "Rank 0.238736451 \n",
      " Question I am facing a hydration error in my Next.js project after trying to animate a dropdown menu, and my styles are not being applied even though they are showing. How can I resolve this? \n",
      " Answer: \n",
      " To resolve the hydration error and styling issues in your Next.js project, first restart the server and inspect the styles using the browser's inspect element tool to ensure Tailwind CSS is being applied. If the styles are not applied, verify that Tailwind CSS is correctly set up by referring to the Tailwind documentation. Undoing changes might temporarily fix the error but can also remove styles, so ensure your Tailwind setup is correct and consistent with the documentation.\n",
      "------------------------\n",
      "Rank 0.151725352 \n",
      " Question How can I build a second brain app using Recoil to fetch all data when the /dashboard component loads and ensure the UI updates immediately with backend synchronization for create, edit, and delete operations? \n",
      " Answer: \n",
      " To build the second brain app using Recoil, you should use an atom to store the state of your data. Combine this with a useEffect hook to fetch the initial data from the backend when the /dashboard component loads. This setup will ensure that the UI updates immediately by modifying the atom whenever a user performs create, edit, or delete operations. The useEffect will handle the initial data fetch, and the atom will manage the state updates, ensuring synchronization with the backend.\n",
      "------------------------\n",
      "Rank 0.0508794 \n",
      " Question How does a JWT work, and what is the role of the key in it? \n",
      " Answer: \n",
      " A JWT (JSON Web Token) works by taking a string and converting it into a token that can be used for authentication. The key plays a crucial role in signing and verifying the token, ensuring it hasn't been tampered with. The process involves creating a token with three parts: the payload, the secret key, and the expiry time. The secret key is essential for the server to verify the authenticity of the token sent by the client. It does not encrypt or decrypt the token but is used to sign and verify it, allowing the server to confirm the token's validity before permitting any client activities.\n",
      "------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Exiting\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhruv/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "while True:\n",
    "    user_input = input(f\"Input Prompt: \")\n",
    "    if user_input=='exit':\n",
    "        print( 'Exiting')\n",
    "        sys.exit()\n",
    "    if user_input == '':\n",
    "        continue\n",
    "    \n",
    "    docs = get_relevant_pairs(user_input,ADMIN_ID,COURSE_ID,TOPIC_ID)\n",
    "        \n",
    "    for doc in docs:\n",
    "        print(f\"Rank {doc['score']} \\n Question {doc['question']} \\n Answer: \\n {doc['answer']}\")\n",
    "        print(\"------------------------\")\n",
    "\n",
    "    print(\"------------------------------------------------------------------------------------------------------------------------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, our pipeline is complete and we can now move on to the next steps which is sending these relvant documents to the LLM to answer our query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template for the LLM\n",
    "Here, we will need to define the prompt for the LLM to answer the query. The LLM will be given the query and the relevant documents, and it will be expected to return the answer to the query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prompt_template = \"\"\"\n",
    "    You are a specialised AI context aware doubt solver working at an edtech startup, and you will be assisting the users to answer their queries based on previous intrcutors and TAs solved queries.\n",
    "    You will be given a query by the user and the top relevant documents and you have to use those to answer the query asked by the user, which will be given to you below. \n",
    "    In the relevant documents,you will be given the id of the conversation, the cosine similarity score, the question which was aksed by previous student and the answers by the TAs, along with the id of the QA pair. \n",
    "    YOU MUST tell the user that they can explore this further by going to that thread (give them the id) and looking at the entire conversation for better understanding. (Think of this as a reference to build authenticity, as you mention the id).\n",
    "    \n",
    "    \\n\\n User Query : {query}\n",
    "    \\n\\n Documents : {documents}\n",
    "    \n",
    "    MAKE SURE YOU DO NOT ANSWER FROM ANYTHING APART FROM THE DOCUMENTS GIVEN TO YOU. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\",\"documents\"],\n",
    "    template=query_prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the LLM Client and Chain for RAG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    temperature = 0,  \n",
    "    model = \"gpt-4o\",\n",
    "    openai_api_key = OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=query_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A System using the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from LLM:\n",
      "To address the hydration error you're experiencing in your Next.js project while trying to animate a dropdown menu, you can follow these steps based on a similar issue resolved previously:\n",
      "\n",
      "1. **Restart the Server**: Sometimes, simply restarting the server can resolve hydration errors.\n",
      "\n",
      "2. **Inspect Styles**: Use the browser's inspect element tool to check if Tailwind CSS is being loaded correctly. If the styles are visible but not applied, it might indicate a configuration issue with Tailwind CSS.\n",
      "\n",
      "3. **Verify Tailwind Configuration**: Ensure that your Tailwind CSS is set up correctly in your project. This involves checking your Tailwind configuration file to make sure the necessary classes are being generated and applied.\n",
      "\n",
      "For a more detailed understanding, you can explore the entire conversation related to this issue by visiting the thread with the ID: 9cef8bde-c6a7-4758-a736-7d2097c0b38a. This will provide you with additional context and insights that might be helpful in resolving your issue.\n"
     ]
    }
   ],
   "source": [
    "user_query = \"I was having issues in my NEXTJS project, as I tried to animate the dropdown menu, I got a hydration error.\"\n",
    "docs = get_relevant_pairs(user_query,ADMIN_ID,COURSE_ID,TOPIC_ID)\n",
    "\n",
    "# Run the chain\n",
    "response = query_chain.invoke({\n",
    "    \"query\": user_query,\n",
    "    \"documents\": docs\n",
    "})\n",
    "\n",
    "# Print the response\n",
    "print(\"Response from LLM:\")\n",
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have successfully built the RAG model and the Q&A system using the chain. With this, we get the functionality to query the relevant documents and get the answer to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from LLM:\n",
      "A JWT (JSON Web Token) works by taking a string and converting it into a token that can be used for authentication. The key plays a crucial role in signing and verifying the token, ensuring that it hasn't been tampered with. It does not encrypt or decrypt the token but is used to sign the token on the server side. The JWT consists of three parts: the payload, the secret key, and the expiry time. The secret key is essential for the server to verify the authenticity of the token sent by the client. If the token is valid, the server allows the client to proceed with further activities.\n",
      "\n",
      "For a more detailed understanding, you can explore this further by looking at the entire conversation in the thread with the ID: 2cef8bde-d6a7-4758-a736-7d2097c0b38a.\n"
     ]
    }
   ],
   "source": [
    "user_query = \"I am so confused about how JWT works...\"\n",
    "docs = get_relevant_pairs(user_query,ADMIN_ID,COURSE_ID,TOPIC_ID)\n",
    "\n",
    "# Run the chain\n",
    "response = query_chain.invoke({\n",
    "    \"query\": user_query,\n",
    "    \"documents\": docs\n",
    "})\n",
    "\n",
    "# Print the response\n",
    "print(\"Response from LLM:\")\n",
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting via Pinecone (Listing indexes with prefix and then deleting the index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"qa-pairs\"\n",
    "\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "list1 = []\n",
    "for ids in index.list(prefix=f\"{ADMIN_ID}_{COURSE_ID}_{TOPIC_ID}_\"):\n",
    "  list1.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEY = \"d359d72b-40e8-4e9f-b567-62d77f273113_d0305607-30cf-4dfb-ba84-5dc407d9d5bf_e766a834-d346-4265-8e5e-78e0832cabf0_2cef8bde-c6a7-4758-b736-7d2097c0b38a\"\n",
    "res = index.delete([ids for ids in index.list(prefix=KEY)])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQS Data Download\n",
    "Now, since the conversation will be stored in an SQS from the chat history, we will have to download the data from the SQS and then process it to get the conversation JSON. For that, first we would need to connect to the AWS client and initialise the SQS client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "import time,boto3\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "QA_BASE_MODIFICATION_QUEUE_URL = os.getenv(\"QA_BASE_MODIFICATION_QUEUE_URL\")\n",
    "QA_BASE_MODIFICATION_NOTIFICATIONS_ARN = os.getenv(\"QA_BASE_MODIFICATION_NOTIFICATIONS_ARN\")\n",
    "PINECONE_QA_BASE_INDEX_NAME = os.getenv(\"PINECONE_QA_BASE_INDEX_NAME\")\n",
    "\n",
    "while not pc.describe_index(PINECONE_QA_BASE_INDEX_NAME).status['ready']:\n",
    "    time.sleep(1)\n",
    "    \n",
    "# Pinecone Index instance\n",
    "index_qa_base = pc.Index(PINECONE_QA_BASE_INDEX_NAME)\n",
    "\n",
    "# AWS SQS and SNS instances\n",
    "QA_base_SQS_client = boto3.resource(\n",
    "    'sqs',\n",
    "    region_name = \"ap-south-1\",\n",
    "    aws_access_key_id = AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key = AWS_SECRET_ACCESS_KEY\n",
    ")\n",
    "\n",
    "QA_base_SQS_queue = QA_base_SQS_client.Queue(QA_BASE_MODIFICATION_QUEUE_URL)\n",
    "\n",
    "QA_base_SNS_client = boto3.resource(\n",
    "    \"sns\",\n",
    "    region_name = \"ap-south-1\",\n",
    "    aws_access_key_id = AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key = AWS_SECRET_ACCESS_KEY\n",
    ")\n",
    "\n",
    "QA_base_SNS_topic = QA_base_SNS_client.Topic(QA_BASE_MODIFICATION_NOTIFICATIONS_ARN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pusing Update Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileContent = {\n",
    "    \"question\" : \"Test Question 2\",\n",
    "    \"answer\" : \"Test Answer 2\"\n",
    "}\n",
    "\n",
    "file = {\n",
    "    \"thread_id\" : \"Test ID 2\",\n",
    "    \"content\" : fileContent\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_base_S3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    region_name = \"ap-south-1\",\n",
    "    aws_access_key_id = AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key = AWS_SECRET_ACCESS_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'R1YHASVZRJT896X5',\n",
       "  'HostId': 'w2XybhlCBYYryaXUPN5v1gANTE7RE7jL+c8PJ9F9eWvUEKCNbRx3rxLFEoT3uz0l4KkC02EyMpI=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'w2XybhlCBYYryaXUPN5v1gANTE7RE7jL+c8PJ9F9eWvUEKCNbRx3rxLFEoT3uz0l4KkC02EyMpI=',\n",
       "   'x-amz-request-id': 'R1YHASVZRJT896X5',\n",
       "   'date': 'Mon, 03 Feb 2025 11:32:33 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"b7dd36f31f5d21fdb846b156ce1e555a\"',\n",
       "   'x-amz-checksum-crc32': '1Kni7Q==',\n",
       "   'x-amz-checksum-type': 'FULL_OBJECT',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"b7dd36f31f5d21fdb846b156ce1e555a\"',\n",
       " 'ChecksumCRC32': '1Kni7Q==',\n",
       " 'ChecksumType': 'FULL_OBJECT',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_base_S3_client.put_object(\n",
    "    Bucket = \"100xsageqabase\",\n",
    "    Key = \"kirat/test.txt\",\n",
    "    Body = json.dumps(file)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pushing Dummy Data to SQS\n",
    "This process will directly be done by the backend. For now, we will push the dummy data to the SQS and then download the data from the SQS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADMIN_ID_QA = os.getenv(\"ADMIN_ID_QA\")\n",
    "COURSE_ID_QA = os.getenv(\"COURSE_ID_QA\")\n",
    "TOPIC_ID_QA = os.getenv(\"TOPIC_ID_QA\")\n",
    "threadID = \"2cef8bde-d6a7-4758-a736-7d2097c0b38a\"\n",
    "fullPath = \"kirat/cohort3/webDev/QA_Pairs/2cef8bde-d6a7-4758-a736-7d2097c0b38a/QUERY_TRIAL_QS_JSON.txt\"\n",
    "url = \"https://100xsageqabase.s3.ap-south-1.amazonaws.com/kirat/cohort3/webDev/QA_Pairs/2cef8bde-d6a7-4758-a736-7d2097c0b38a/QUERY_TRIAL_QS_JSON.txt?response-content-disposition=inline&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEPn%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCmFwLXNvdXRoLTEiRzBFAiEAvM6D7arSnHYtMzqGCAYOoxKq0UjhImhZNSF1FdsoHUACIBjSCj3%2Bp7okSsgq78Cod0BN7L9AXroBmG5jQnKDjIWRKuADCBIQABoMNzY3Mzk4MTI1NTUyIgyFbi1AgK0068%2BPstoqvQMuUrxWSc3U8JCB7KvV3YTIhk%2Bl1y0FZmXTOlOn8%2BQHfKAQY9%2FujKJRbgYk36IyBSldJO791Qf90Hjne3DN9%2BO1fiU%2Fa5NF8zYAuQ2ARbmRtiJYJ3ifGyXL4P1jLMDZ7BFzOMaR49YfKOQysNcyrhDHyiQ26z0WrLRo5b0qcc5WKpMN14LupjD0slY2Bd2jvedH5otbsxx%2FurSAk1v7Vl5yRPMI2t%2FjCcnFRWU65%2F41d20%2BNQhh1zNUFT7PUkvBIzmjSnts%2BXguEaS9owpuc3nn%2BxlgGbXNAgqAfOBHPAU6qo%2F3u05RpWxur%2BSrYHN1MAnFwdKbjNEUn0IK6LOnbx9RmXqFDqylmIO3TFLnOAYl2uUklH7%2FLdB6ajWQ%2Bb7n9iFM0U%2BtqncruPnOvjoOv0Y9XKvnnoMwyqxtttbL9D1zyMCn2pgJoesl%2F%2FNzW1wigiX%2Fl5Dnt23sBN0OlujKjbvnJ6phEgMHyrvT18Av6yOELFMFZp2C5yZTRU%2B4pR%2BQasDfm7juOPLSPfnzwVg9COz8nNpQq8NE296z6Mdr7yOUXLZSK8VCGG6QQ8sWAGdiHC3fKLZshfr2NaVR882DMJHBgb0GOuQCLRHQJK%2F%2FPpgBKC6UO2y9Z6dlIRBoOs0wmludh99cynCkn7hZh%2BZl3D6tMUfw3ial2V%2FczOzi%2BpfAllgsBIDLvTxOIPuIi3%2F6UmHmIa3ImP9gtex4Z63N1%2FqCov4AXFn0u3vhxh8APjeBrSJ36kR9a%2FXbBfTBbawMMKsU0ac%2Fa8KHdPl5czkJUmYf20kTrUXxiHB7z1EiVT3Jo%2F2to80fm2P7hWku5yYprBI2n5iLMHaE4yf1KD1BmaXIuJJ19zLcuPgWiX8lNQ%2FYQOP90yQYW7unb6aURXtVI077KfFKCzqfN3L2qO1LsPHI74TXCdY5V9iz45WfYiOV60muzfcGbD5kOvE%2BZAhu6glGmMn3B1N3inFFUs%2Fx%2Fqslk8e8onHS%2BURqaMhFOQw3VndGPNNnmmZbGwVTOWGZp7tYheRBOPfc4%2BK8tFqciZKhhuzCJXmM%2Fg4mfSzkTkIti8rDUQDt%2BSO%2Fie8%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIA3FLD6D7YKUY5DUMY%2F20250203%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20250203T085749Z&X-Amz-Expires=1800&X-Amz-SignedHeaders=host&X-Amz-Signature=4fb13ef8e220169585dd84209465fb48db0b671621324516449c419b443658e4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us load the text as Document and then extract the conversation JSON from the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_QA_data(file_url):\n",
    "    \"\"\"\n",
    "    Function to classify the file as either a text or PDF file, download it from a given URL,\n",
    "    and return the finalised QA as a string.\n",
    "\n",
    "    Args:\n",
    "        file_url (str): The URL of the file to be classified\n",
    "\n",
    "    Returns:\n",
    "        data : The text parseable JSON of the conversation\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(file_url)\n",
    "        response.raise_for_status()  \n",
    "\n",
    "        responseContent = response.content\n",
    "        data = responseContent.decode('UTF-8')\n",
    "\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        raise Exception(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{ \"Samim Rezvi OP\": \"how does a jwt work...like it takes a string and converts it into something random...what is the role of key here? @TA Harry Potter @TA Sumana @TA SerBarristan\",     \"TA Harry Potter\": \"google kiya?\",     \"Samim Rezvi OP (response)\": \"yes key ka role samajh nhi aya\",     \"TA Harry Potter (clarification)\": \"it\\'s that, allows verification that the token wasn\\'t tampered with.\",     \"Samim Rezvi OP (clarification request)\": \"mtlb key encrypt and decrypt krta hai na?\",     \"TA Harry Potter (clarification final)\": \"Nahi, JWT ke case mein key encrypt aur decrypt nahi karti, balki sign aur verify karne ke liye use hoti hai.\",     \"akshiiittt\": \"Basically jwt authentication mein kaam aati hai, like vo ek random kuch text generate karta hai jisko ham sign ki madad se create karte hai jismein ham 3 values pass on krte, first one is the payload second is the secret key(jo sabse main hai jiski help se hi server verfiy kar pata hai ki ki jwt jo genrate hua hai voh sahi hai ya galat and third pe expiry time of that token). This is basically the main thing of the jwt and second verify hota hai jo client se send hota hai and server compare karta hai secret ki help se yeh sahi token hai ke nahi and then hi allow karta hai client ko aggey kuch bhi activities karne ke liye.\",     \"Samim Rezvi OP (final)\": \"accha...samajh gya.... thanks man\"}'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = load_QA_data(url)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push SQS Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "push_response = QA_base_SQS_queue.send_message(\n",
    "    MessageBody = \"POST\",\n",
    "    DelaySeconds =  5,\n",
    "    MessageAttributes =  { \n",
    "        \"link\": { \n",
    "            \"DataType\": \"String\", \n",
    "            \"StringValue\": url, \n",
    "        },\n",
    "        \"key\": { \n",
    "            \"DataType\": \"String\", \n",
    "            \"StringValue\": fullPath, \n",
    "        },\n",
    "        \"properties\": { \n",
    "            \"DataType\": \"String\", \n",
    "            \"StringValue\": json.dumps({ \n",
    "                \"admin_id\" : ADMIN_ID_QA ,\n",
    "                \"course_id\" : COURSE_ID_QA,\n",
    "                \"topic_id\" : TOPIC_ID_QA,\n",
    "                \"thread_id\" : threadID\n",
    "            }) \n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Receive and Handle SQS Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text) :\n",
    "    \"\"\"\n",
    "        Function to convert the text string into embeddings using text-embedding-3-small from OpenAI\n",
    "    \n",
    "        Args:\n",
    "            text : A string which will contain either the text chunk or the user query\n",
    "            \n",
    "        Returns:\n",
    "            vector : A vector of 1536 dimensions\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = embedding_model.create(\n",
    "            input=text,\n",
    "            model=\"text-embedding-3-small\"\n",
    "        )\n",
    "        \n",
    "        return response.data[0].embedding   \n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_summariser_thread = openAI_client.beta.threads.create()\n",
    "QA_SUMMARISER_OPENAI_ASSISTANT_ID = os.getenv(\"QA_SUMMARISER_OPENAI_ASSISTANT_ID\")\n",
    "\n",
    "\n",
    "def create_QAPair(conversation):\n",
    "    \"\"\" \n",
    "    Function to generate a question-answer pair from a given conversation. The primary aim would be to push \n",
    "    a conversation to the QA summariser thread and run the thread for the assistant to generate a question-answer pair.\n",
    "\n",
    "    Args:\n",
    "        conversation (string): An JSON parsable string object of string key value pairs, where each key is the sender and each value is their message \n",
    "        from them.\n",
    "\n",
    "    Returns:\n",
    "        run : The run object from OpenAI Assistants (https://platform.openai.com/docs/api-reference/runs/object)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        openAI_client.beta.threads.messages.create(\n",
    "            thread_id=qa_summariser_thread.id,\n",
    "            role=\"user\",\n",
    "            content= [{\n",
    "                \"type\" : \"text\",\n",
    "                \"text\" : conversation\n",
    "            }]\n",
    "        )\n",
    "                \n",
    "        run = openAI_client.beta.threads.runs.create(\n",
    "            thread_id=qa_summariser_thread.id,\n",
    "            assistant_id=QA_SUMMARISER_OPENAI_ASSISTANT_ID,\n",
    "        )\n",
    "        \n",
    "        return run\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(e,sys)\n",
    "\n",
    "def get_QAPair(thread, run):\n",
    "    \"\"\" \n",
    "    Function to get the Q&A pair generated by the assistant in the thread and run provided.\n",
    "\n",
    "    Args:\n",
    "        1. thread : The thread object from OpenAI Assistants (https://platform.openai.com/docs/api-reference/threads/object)\n",
    "        2. run : The run object from OpenAI Assistants (https://platform.openai.com/docs/api-reference/runs/object)\n",
    "\n",
    "    Returns:\n",
    "        messages : The messages object from OpenAI Assistants (https://platform.openai.com/docs/api-reference/messages/object)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        while True:\n",
    "            run = openAI_client.beta.threads.runs.retrieve(\n",
    "                thread_id=thread.id,\n",
    "                run_id=run.id\n",
    "            )\n",
    "            if run.status == 'completed':\n",
    "                messages = openAI_client.beta.threads.messages.list(\n",
    "                    thread_id=thread.id\n",
    "                )\n",
    "                return messages\n",
    "            elif run.status in ['failed', 'cancelled', 'expired']:\n",
    "                raise Exception(f\"Run ended with status: {run.status}\")\n",
    "            time.sleep(1)\n",
    "    except Exception as e:\n",
    "        raise Exception(e)\n",
    "\n",
    "def get_QA(conversation,thread_id):\n",
    "    \"\"\"\n",
    "        Function to get the Q&A pair generated given the conversation and prepare it as a dictionary, with conversation ID as the key (dummy id generated using uuid for now).\n",
    "        \n",
    "        Args:\n",
    "            conversation : A dictionary containing the conversation between the user and the assistant\n",
    "            \n",
    "        Returns:\n",
    "            QA : A dictionary containing the Q&A pair generated by the assistant\n",
    "    \"\"\"\n",
    "    try : \n",
    "        QA = {}\n",
    "\n",
    "        run = create_QAPair(conversation)\n",
    "        messages = get_QAPair(qa_summariser_thread, run)\n",
    "        \n",
    "        if(messages):\n",
    "            QA[thread_id] = messages.data[0].content[0].text.value\n",
    "        else:\n",
    "            QA[thread_id] = {\"question\" : \"Not available\", \"answer\" : \"Not available\"}\n",
    "            raise Exception(\"No Q&A pair generated by the assistant\")\n",
    "            \n",
    "        return QA\n",
    "    except Exception as e:\n",
    "        raise Exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_QA_vector(QA,ADMIN_ID,COURSE_ID,TOPIC_ID):\n",
    "    \"\"\"\n",
    "        Function to convert the Q&A pair into pinecone records to upsert into our index\n",
    "    \n",
    "        Args:\n",
    "            QA : A dictionary containing the conversation id, and the Q&A pair string as a parsable json generated by the assistant\n",
    "            ADMIN_ID : The userID of the admin who created this document, used to store in metadata of record\n",
    "            COURSE_ID : The courseID of the course the chunk is from, used to store in metadata of record\n",
    "            TOPIC_ID : The topicID of the topic the chunk is from, used to store in metadata of record\n",
    "            \n",
    "        Returns:\n",
    "            entry : A final pinecone record\n",
    "    \"\"\"\n",
    "    try:\n",
    "        entry = {}\n",
    "        \n",
    "        QA_ID = list(QA.keys())[0]\n",
    "        QA_Pair = json.loads(QA[QA_ID])\n",
    "        \n",
    "        entry[\"id\"] = f\"{ADMIN_ID}_{COURSE_ID}_{TOPIC_ID}_{QA_ID}\"\n",
    "        \n",
    "        question = QA_Pair[\"question\"]\n",
    "        answer = QA_Pair[\"answer\"]\n",
    "        text = \"Question : \" + question + \"\\nAnswer : \" + answer\n",
    "        \n",
    "        entry[\"values\"] = get_embedding(text)\n",
    "        entry[\"metadata\"] = {\n",
    "            \"ADMIN_ID\" : ADMIN_ID,\n",
    "            \"COURSE_ID\" : COURSE_ID,\n",
    "            \"TOPIC_ID\" : TOPIC_ID,\n",
    "            \"QA_ID\" : QA_ID,\n",
    "            \"question\" : question,\n",
    "            \"answer\" : answer\n",
    "        }\n",
    "            \n",
    "        return entry\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_QA_vectors(vector):\n",
    "    \"\"\"\n",
    "        Function to upsert the vector records into the index\n",
    "    \n",
    "        Args:\n",
    "            vector : The collection of records as defined above\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        record_status = index_qa_base.upsert(\n",
    "            vectors=[vector]\n",
    "        )  \n",
    "        \n",
    "        upserted_count = record_status.get(\"upserted_count\", len(vector))\n",
    "        print(f\"Total records upserted successfully: {upserted_count}\")\n",
    "        \n",
    "        return record_status\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA Base Processing\n",
    "import validators\n",
    "\n",
    "\n",
    "def process_post_message_QA_base(message_info: dict):\n",
    "    link = message_info[\"link\"][\"StringValue\"]\n",
    "\n",
    "    if not validators.url(link):\n",
    "        raise Exception(\"Invalid URL provided to access file.\")\n",
    "\n",
    "    key = message_info[\"key\"][\"StringValue\"]\n",
    "    properties = json.loads(message_info[\"properties\"][\"StringValue\"])\n",
    "    adminID = properties[\"admin_id\"]\n",
    "    courseID = properties[\"course_id\"]\n",
    "    topicID = properties[\"topic_id\"]\n",
    "    QA_ID = properties[\"thread_id\"]\n",
    "\n",
    "    \n",
    "    if(validators.url(link)):\n",
    "        key = key.replace(\" \", \"_\")\n",
    "      \n",
    "        conversation = load_QA_data(link)\n",
    "        print(\"Initial conversation loaded\")\n",
    "\n",
    "        QA = get_QA(conversation,QA_ID)\n",
    "        print(\"Chunked documents set.\")\n",
    "        \n",
    "        vector = create_QA_vector(QA,adminID,courseID,topicID)\n",
    "        print(\"Records list created.\")\n",
    "        \n",
    "        record_status = upsert_QA_vectors(vector)\n",
    "        final_upload_status = {\"response\": {\"upserted_count\": record_status.get('upserted_count', 0)}}\n",
    "        print(\"Records uploaded.\")\n",
    "        \n",
    "    else :\n",
    "        raise Exception(status_code=400, detail=\"Invalid link type\")\n",
    "    \n",
    "    \n",
    "    if final_upload_status[\"response\"][\"upserted_count\"] > 0:\n",
    "        print(\"Document Successfully Upserted at VectorDB\")\n",
    "\n",
    "        push_notification = {\"status\": 201, \"detail\": \"Your QA has been added to the analysis database.\"}\n",
    "        sns_notification_response = QA_base_SNS_topic.publish(\n",
    "            Message=json.dumps(push_notification),\n",
    "            Subject=\"POST QA Notification\",\n",
    "            MessageAttributes={\"key\": {\"DataType\": \"String\", \"StringValue\": key}},\n",
    "        )\n",
    "\n",
    "        if sns_notification_response[\"ResponseMetadata\"][\"HTTPStatusCode\"] == 200:\n",
    "            success_message = \"Document successfully added to the analysis database and notification sent to user.\"\n",
    "            return {\"statusCode\": 200, \"body\": json.dumps({\"message\": success_message})}\n",
    "        else:\n",
    "            raise Exception(\"An error occurred while sending the notification to the user\")\n",
    "    else:\n",
    "        raise Exception(\"An error occurred while upserting the vector\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_QA_vectors(qa_id,ADMIN_ID,COURSE_ID,TOPIC_ID):\n",
    "    \"\"\"\n",
    "        Function to delete vectors associated to a given document\n",
    "    \n",
    "        Args:\n",
    "            qa_id : The id of the document, used to match prefix of records\n",
    "            ADMIN_ID : The userID of the admin who created this document, used to store in metadata of record\n",
    "            COURSE_ID : The courseID of the course the chunk is from, used to store in metadata of record\n",
    "            TOPIC_ID : The topicID of the topic the chunk is from, used to store in metadata of record\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        res = index_qa_base.delete([ids for ids in index_qa_base.list(prefix = f\"{ADMIN_ID}_{COURSE_ID}_{TOPIC_ID}_{qa_id}\")])\n",
    "        return res\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(e,sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_delete_message_QA_base(message_info: dict):\n",
    "    key = message_info[\"key\"][\"StringValue\"]\n",
    "\n",
    "    properties = json.loads(message_info[\"properties\"][\"StringValue\"])\n",
    "    adminID = properties[\"admin_id\"]\n",
    "    courseID = properties[\"course_id\"]\n",
    "    topicID = properties[\"topic_id\"]\n",
    "    QA_ID = properties[\"thread_id\"]\n",
    "    \n",
    "    final_response = delete_QA_vectors(QA_ID,adminID,courseID,topicID)\n",
    "    if(final_response=={}):\n",
    "        print(f\"All records associated with {key} deleted successfully\")\n",
    "\n",
    "        push_notification = {\"status\": 200, \"detail\": \"Your QA has been deleted from the analysis database.\"}\n",
    "        sns_notification_response = QA_base_SNS_topic.publish(\n",
    "            Message=json.dumps(push_notification),\n",
    "            Subject=\"DELETE QA Notification\",\n",
    "            MessageAttributes={\"key\": {\"DataType\": \"String\", \"StringValue\": key}},\n",
    "        )\n",
    "\n",
    "        if sns_notification_response[\"ResponseMetadata\"][\"HTTPStatusCode\"] == 200:\n",
    "                success_message = \"QA successfully deleted from the analysis database and notification sent to user.\"\n",
    "                return {\"statusCode\": 200, \"body\": json.dumps({\"message\": success_message})}\n",
    "        else:\n",
    "            raise Exception(\"An error occurred while sending the notification to the user\")\n",
    "    else:\n",
    "        raise Exception(status_code=400, detail=\"Could not delete vectors from pinecone index\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQS Main Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_incoming_SQS_QA_base(message):\n",
    "    request_type = message.body\n",
    "    message_info = message.message_attributes\n",
    "\n",
    "    if request_type and message_info:\n",
    "        if request_type not in [\"POST\", \"DELETE\"]:\n",
    "            raise Exception(\"Invalid request type received from SQS message.\")\n",
    "        else:\n",
    "            if request_type == \"POST\":\n",
    "                res = process_post_message_QA_base(message_info)\n",
    "                if res[\"statusCode\"] == 200:\n",
    "                    body = json.loads(res[\"body\"])\n",
    "                    print(body[\"message\"])\n",
    "                    deleteMessage = QA_base_SQS_queue.delete_messages(Entries=[{\"Id\": message.message_id, \"ReceiptHandle\": message.receipt_handle}])\n",
    "                    \n",
    "                    if deleteMessage[\"ResponseMetadata\"][\"HTTPStatusCode\"] == 200:\n",
    "                        print(\"Message deleted from SQS post processing\")\n",
    "                        \n",
    "                    else:\n",
    "                        raise Exception(\"An error occurred while deleting the message from SQS post processing\")\n",
    "                else:\n",
    "                    raise Exception(\"An error occurred while processing the post request\")\n",
    "                \n",
    "            elif request_type == \"DELETE\":\n",
    "                res = process_delete_message_QA_base(message_info)\n",
    "                if res[\"statusCode\"] == 200:\n",
    "                    body = json.loads(res[\"body\"])\n",
    "                    print(body[\"message\"])\n",
    "                    deleteMessage = QA_base_SQS_queue.delete_messages(Entries=[{\"Id\": message.message_id, \"ReceiptHandle\": message.receipt_handle}])\n",
    "                    \n",
    "                    if deleteMessage[\"ResponseMetadata\"][\"HTTPStatusCode\"] == 200:\n",
    "                        print(\"Message deleted from SQS post processing\")\n",
    "                        \n",
    "                    else:\n",
    "                        raise Exception(\"An error occurred while deleting the message from SQS post processing\")\n",
    "                else:\n",
    "                    raise Exception(\"An error occurred while processing the delete request\")\n",
    "                \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = openAI_client.embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete SQS Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "push_response = QA_base_SQS_queue.send_message(\n",
    "    MessageBody = \"DELETE\",\n",
    "    DelaySeconds =  5,\n",
    "    MessageAttributes =  { \n",
    "        \"key\": { \n",
    "            \"DataType\": \"String\", \n",
    "            \"StringValue\": fullPath, \n",
    "        },\n",
    "        \"properties\": { \n",
    "            \"DataType\": \"String\", \n",
    "            \"StringValue\": json.dumps({ \n",
    "                \"admin_id\" : ADMIN_ID_QA ,\n",
    "                \"course_id\" : COURSE_ID_QA,\n",
    "                \"topic_id\" : TOPIC_ID_QA,\n",
    "                \"thread_id\" : threadID\n",
    "            }) \n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All records associated with kirat/cohort3/webDev/QA_Pairs/2cef8bde-d6a7-4758-a736-7d2097c0b38a/QUERY_TRIAL_QS_JSON.txt deleted successfully\n",
      "QA successfully deleted from the analysis database and notification sent to user.\n",
      "Message deleted from SQS post processing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(message \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     11\u001b[0m         process_incoming_SQS_QA_base(message)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "        response = QA_base_SQS_queue.receive_messages(\n",
    "            MaxNumberOfMessages=1,\n",
    "            MessageAttributeNames=[\"All\"],\n",
    "            VisibilityTimeout=10,\n",
    "        )\n",
    "\n",
    "        if response:\n",
    "            message = response[0]\n",
    "            if(message is not None):\n",
    "                process_incoming_SQS_QA_base(message)\n",
    "\n",
    "        time.sleep(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
